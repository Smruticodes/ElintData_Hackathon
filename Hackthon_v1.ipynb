{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ6MAaWbQycD",
        "outputId": "e0b88358-3627-4dbf-c6f1-124acddeca72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting imapclient\n",
            "  Downloading IMAPClient-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading IMAPClient-3.0.1-py2.py3-none-any.whl (182 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/182.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imapclient\n",
            "Successfully installed imapclient-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install imapclient\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIDVi4KjQ3IT",
        "outputId": "eef28c85-98eb-4b9a-93cd-cb3fe51823de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask-cors\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Requirement already satisfied: flask>=0.9 in /usr/local/lib/python3.11/dist-packages (from flask-cors) (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.11/dist-packages (from flask-cors) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=0.9->flask-cors) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=0.9->flask-cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=0.9->flask-cors) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=0.9->flask-cors) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug>=0.7->flask-cors) (3.0.2)\n",
            "Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESQDVc65RC2S",
        "outputId": "2666fd13-fb32-49f5-c8c7-c80d554e386f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Retrieving folder contents\n",
            "Processing file 1xZLm3WKbaxvOGZJhQvOJmFFGoZKDUKFa $Rajakannan_cv.pdf\n",
            "Processing file 1r8RsEMiJSBmnBg3TZLaGVex6_U-Evk39 1 Durgesh Resume Updated Nov-24.pdf\n",
            "Processing file 1SecvnEf4AJ0NC4XtcgwcccCa9Lg6qwVt 2022TT12175_tech_phase2.pdf\n",
            "Processing file 1K6j7SXDenMmm5leR_FtX1YlltnUsynZC Aakarsh.pdf\n",
            "Processing file 1ZDIThOgTh4nAOo-HzR107t4YtUbOkRLF Aayush Sourav.pdf\n",
            "Processing file 1ycoD6qtrvv_hs-0r_slk36YCjo1W6EiX Abinand.pdf\n",
            "Processing file 1SOKgBOWxlxfxegpK5uNp3FGxP5PgGBlv aby@softdev.pdf\n",
            "Processing file 1G13uJF_k6l026bOMrnctJ1q46S4JSoEh Aditya Maurya_DS.pdf\n",
            "Processing file 1tI3PVp1Fri4oTB27dZJlWCqt5RAKOO5H ai_cv.pdf\n",
            "Processing file 1fTfO7n-h3CvEzj1t_nmvZ3GBDeBcC5U1 AjayrajCV.pdf\n",
            "Processing file 1lW8A-ge_YxBNtD_V0AOYgfq_kHBP0yqi anand_resume.pdf\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xZLm3WKbaxvOGZJhQvOJmFFGoZKDUKFa\n",
            "To: /content/cv_folder/$Rajakannan_cv.pdf\n",
            "100% 42.7k/42.7k [00:00<00:00, 56.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1r8RsEMiJSBmnBg3TZLaGVex6_U-Evk39\n",
            "To: /content/cv_folder/1 Durgesh Resume Updated Nov-24.pdf\n",
            "100% 216k/216k [00:00<00:00, 8.56MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SecvnEf4AJ0NC4XtcgwcccCa9Lg6qwVt\n",
            "To: /content/cv_folder/2022TT12175_tech_phase2.pdf\n",
            "100% 57.9k/57.9k [00:00<00:00, 11.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K6j7SXDenMmm5leR_FtX1YlltnUsynZC\n",
            "To: /content/cv_folder/Aakarsh.pdf\n",
            "100% 123k/123k [00:00<00:00, 12.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZDIThOgTh4nAOo-HzR107t4YtUbOkRLF\n",
            "To: /content/cv_folder/Aayush Sourav.pdf\n",
            "100% 666k/666k [00:00<00:00, 11.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ycoD6qtrvv_hs-0r_slk36YCjo1W6EiX\n",
            "To: /content/cv_folder/Abinand.pdf\n",
            "100% 63.2k/63.2k [00:00<00:00, 8.98MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SOKgBOWxlxfxegpK5uNp3FGxP5PgGBlv\n",
            "To: /content/cv_folder/aby@softdev.pdf\n",
            "100% 22.1k/22.1k [00:00<00:00, 49.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1G13uJF_k6l026bOMrnctJ1q46S4JSoEh\n",
            "To: /content/cv_folder/Aditya Maurya_DS.pdf\n",
            "100% 22.9k/22.9k [00:00<00:00, 72.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tI3PVp1Fri4oTB27dZJlWCqt5RAKOO5H\n",
            "To: /content/cv_folder/ai_cv.pdf\n",
            "100% 124k/124k [00:00<00:00, 4.60MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fTfO7n-h3CvEzj1t_nmvZ3GBDeBcC5U1\n",
            "To: /content/cv_folder/AjayrajCV.pdf\n",
            "100% 160k/160k [00:00<00:00, 6.76MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lW8A-ge_YxBNtD_V0AOYgfq_kHBP0yqi\n",
            "To: /content/cv_folder/anand_resume.pdf\n",
            "100% 117k/117k [00:00<00:00, 12.2MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gdown\n",
        "\n",
        "# Use the folder ID, NOT the full URL\n",
        "!gdown --folder https://drive.google.com/drive/folders/1oHqsZrJ5jQavIlIzKanyJ6TLEjbIxTbT\n",
        "\n",
        "\n",
        "# # Unzip the file\n",
        "# !unzip -q folder.zip -d extracted_folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf9wcJa5RIHx",
        "outputId": "bceda256-06db-4a5f-b42d-723bb2457910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kwdPlpts8O_7DnQjWiQ563LLxk_I63iH\n",
            "To: /content/job_description.pdf\n",
            "100% 74.2k/74.2k [00:00<00:00, 59.1MB/s]\n",
            "-rw-r--r-- 1 root root 73K Apr 13 13:21 job_description.pdf\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1kwdPlpts8O_7DnQjWiQ563LLxk_I63iH --output job_description.pdf\n",
        "\n",
        "# Verify the download\n",
        "!ls -lh job_description.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOkHPZVnRKzr",
        "outputId": "c867cfa6-82e4-42e1-cd9e-e7493daed91e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.34.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyngrok==4.1.1) (1.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyngrok==4.1.1) (6.0.2)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15963 sha256=1ca74409e2d8da92ae880dd7d4c2670f6fe79fd98af120d281b09ef165951719\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/e2/28/275496a22cb15fb495458aed2b164b4ccaa10e2f44188fb0b9\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.1)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313502 sha256=8dcd18025525a0c06a67d08cc3b4fdebd876f8a769279599d6076dd21864fe2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: PyMuPDF, pybind11, fasttext\n",
            "Successfully installed PyMuPDF-1.25.5 fasttext-0.9.3 pybind11-2.13.6\n",
            "--2025-04-18 14:21:23--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.34.83, 13.226.34.122, 13.226.34.7, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.34.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  91.1MB/s    in 22s     \n",
            "\n",
            "2025-04-18 14:21:45 (197 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.25.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok==4.1.1\n",
        "!pip install python-docx\n",
        "!pip install PyMuPDF nltk fasttext\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gunzip cc.en.300.bin.gz\n",
        "!pip install PyMuPDF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50CwWW5nRMx7",
        "outputId": "70180ad7-1eee-42b0-cb54-7fa265127968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-0.114.0-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai)\n",
            "  Downloading auth0_python-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
            "Collecting chromadb>=0.5.23 (from crewai)\n",
            "  Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.1.8)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.7.9-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting json-repair>=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.41.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json5>=0.10.0 (from crewai)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm==1.60.2 (from crewai)\n",
            "  Downloading litellm-1.60.2-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.72.0)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.31.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.31.1)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "Requirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.11.3)\n",
            "Collecting python-dotenv>=1.0.0 (from crewai)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai) (2024.11.6)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.6.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.11.15)\n",
            "Collecting httpx<0.28.0,>=0.23.0 (from litellm==1.60.2->crewai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (4.23.0)\n",
            "Collecting tiktoken>=0.7.0 (from litellm==1.60.2->crewai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai) (0.21.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n",
            "Collecting build>=1.0.3 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.10.16)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb>=0.5.23->crewai)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm==1.60.2->crewai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm==1.60.2->crewai) (0.14.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Collecting jiter<0.9,>=0.6.1 (from instructor>=1.3.3->crewai)\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.33.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.30.0->crewai) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.69.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (5.29.4)\n",
            "Collecting opentelemetry-api>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-sdk>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pdfminer.six==20250327 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.0.5)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai) (1.19.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.30.0->crewai) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.60.2->crewai) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.60.2->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai) (0.24.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.60.2->crewai) (0.30.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (15.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.60.2->crewai) (2025.3.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.6.1)\n",
            "Downloading crewai-0.114.0-py3-none-any.whl (285 kB)\n",
            "Downloading litellm-1.60.2-py3-none-any.whl (6.7 MB)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.9.0-py3-none-any.whl (135 kB)\n",
            "Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Downloading instructor-1.7.9-py3-none-any.whl (86 kB)\n",
            "Downloading json_repair-0.41.1-py3-none-any.whl (21 kB)\n",
            "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
            "Downloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
            "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "Downloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading uv-0.6.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53800 sha256=29d0e93f67b44efb4fcc6a7d9de3a16124f10150f664ffe030fcb4003c8ef6de\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, appdirs, uvloop, uvicorn, uv, tomli-w, tomli, python-dotenv, pyproject_hooks, pypdfium2, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, jsonref, json5, json-repair, jiter, jedi, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpx, coloredlogs, build, pyvis, pdfminer.six, opentelemetry-semantic-conventions, onnxruntime, kubernetes, groq, fastapi, auth0-python, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, litellm, instructor, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, crewai\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.9.0\n",
            "    Uninstalling jiter-0.9.0:\n",
            "      Successfully uninstalled jiter-0.9.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.31.1\n",
            "    Uninstalling opentelemetry-api-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-api-1.31.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.31.1\n",
            "    Uninstalling opentelemetry-sdk-1.31.1:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.31.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.10.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.9.0 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 crewai-0.114.0 durationpy-0.9 fastapi-0.115.9 groq-0.22.0 httptools-0.6.4 httpx-0.27.2 humanfriendly-10.0 instructor-1.7.9 jedi-0.19.2 jiter-0.8.2 json-repair-0.41.1 json5-0.12.0 jsonref-1.1.0 kubernetes-32.0.1 litellm-1.60.2 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-exporter-otlp-proto-http-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 overrides-7.7.0 pdfminer.six-20250327 pdfplumber-0.11.6 posthog-3.25.0 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 pyvis-0.3.2 starlette-0.45.3 tiktoken-0.9.0 tomli-2.2.1 tomli-w-1.2.0 uv-0.6.14 uvicorn-0.34.1 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install crewai groq requests PyMuPDF pandas --progress-bar off\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8LtLdL7RPQR",
        "outputId": "614321e8-347c-4167-832b-a2f650fa0bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UqeXBatRRAS",
        "outputId": "b86c66fb-d268-4082-f481-9cf9b233a7d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJxnGQ2cRTP6",
        "outputId": "9dee4c57-2fca-40a6-ad78-8ac7621b8571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADmGHf80Rmmr",
        "outputId": "50601a39-fb1a-4cba-8c4d-83de2e00cf47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flask and Ngrok processes terminated.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import signal\n",
        "import psutil\n",
        "\n",
        "# Function to terminate Flask and Ngrok processes\n",
        "def terminate_flask_ngrok():\n",
        "    # Iterate through all running processes\n",
        "    for proc in psutil.process_iter():\n",
        "        try:\n",
        "            # Check if the process is a Flask or Ngrok process\n",
        "            if proc.name() == \"python\" and \"flask\" in proc.cmdline():\n",
        "                os.kill(proc.pid, signal.SIGTERM)  # Terminate the Flask process\n",
        "            if proc.name() == \"ngrok\":\n",
        "                os.kill(proc.pid, signal.SIGTERM)  # Terminate the Ngrok process\n",
        "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
        "            pass\n",
        "\n",
        "# Call the function to terminate Flask and Ngrok processes\n",
        "terminate_flask_ngrok()\n",
        "print(\"Flask and Ngrok processes terminated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulYOj8nIS4IP",
        "outputId": "6b00a094-f8aa-4ab8-ee2b-afc29481bc11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken <Your Authtoken>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "KkVNIb4uTDC9",
        "outputId": "2a6d240a-a46c-4d3e-87cc-5100d87ced6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (4.1.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.4-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "  Attempting uninstall: pyngrok\n",
            "    Found existing installation: pyngrok 4.1.1\n",
            "    Uninstalling pyngrok-4.1.1:\n",
            "      Successfully uninstalled pyngrok-4.1.1\n",
            "Successfully installed pyngrok-7.2.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b62e5c15729c4c05a35a33b591a4e826",
              "pip_warning": {
                "packages": [
                  "pyngrok"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install pyngrok --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYQnzccZRoLJ",
        "outputId": "1ea84a22-0eb6-4b98-bff2-208be4635d6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "WARNING:pyngrok.process.ngrok:t=2025-04-18T14:28:05+0000 lvl=warn msg=\"ngrok config file found at both XDG and legacy locations, using XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * ngrok tunnel \"NgrokTunnel: \"https://38a0-34-85-176-57.ngrok-free.app\" -> \"http://localhost:5000\"\" -> \"http://127.0.0.1:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Apr/2025 14:29:18] \"GET /download_emails?num_emails=10 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Apr/2025 14:29:33] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import fitz  # PyMuPDF\n",
        "import docx\n",
        "import nltk\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy.spatial.distance import cosine\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from fasttext import load_model\n",
        "from groq import Groq\n",
        "from flask import Flask, request, jsonify\n",
        "import smtplib\n",
        "import ssl\n",
        "import logging\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from pyngrok import ngrok\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "\n",
        "# Ensure you have downloaded NLTK resources if not done:\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Email credentials\n",
        "IMAP_SERVER = \"imap.secureserver.net\"\n",
        "EMAIL_USER = \"Your email\"\n",
        "EMAIL_PASS = \"Your password\"\n",
        "SMTP_SERVER = \"smtp.gmail.com\"\n",
        "SMTP_PORT = 587\n",
        "SENDER_EMAIL = \"dvikash9140@gmail.com\"\n",
        "APP_PASSWORD = \"jwldwdprkwhirkgs\"\n",
        "\n",
        "KEYWORDS = [\"internship\", \"cv\", \"opportunity\", \"resume\", \"application\"]\n",
        "ALLOWED_EXTENSIONS = [\".pdf\", \".doc\", \".docx\"]\n",
        "ATTACHMENTS_FOLDER = \"attachments_all\"\n",
        "os.makedirs(ATTACHMENTS_FOLDER, exist_ok=True)\n",
        "\n",
        "client = Groq(api_key=\"Your Groq api key\")\n",
        "\n",
        "# Flask app setup\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Send email function\n",
        "def send_email(recipient_email, subject, body):\n",
        "    if not recipient_email:\n",
        "        return False, \"No recipient email provided\"\n",
        "    msg = MIMEMultipart()\n",
        "    msg[\"From\"] = SENDER_EMAIL\n",
        "    msg[\"To\"] = recipient_email\n",
        "    msg[\"Subject\"] = subject\n",
        "    msg.attach(MIMEText(body, \"plain\"))\n",
        "\n",
        "    try:\n",
        "        context = ssl.create_default_context()\n",
        "        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n",
        "            server.starttls(context=context)\n",
        "            server.login(SENDER_EMAIL, APP_PASSWORD)\n",
        "            server.sendmail(SENDER_EMAIL, recipient_email, msg.as_string())\n",
        "        return True, \"Sent\"\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "# Extract CV details using Groq\n",
        "def extract_cv_details_groq(cv_text: str):\n",
        "    retries = 5\n",
        "    backoff = 5\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            completion = client.chat.completions.create(\n",
        "                model=\"mistral-saba-24b\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": (\n",
        "                        \"Extract name, email, phone number, years of experience, \"\n",
        "                        \"and programming languages from the CV. \"\n",
        "                        \"Return in plain text using these labels:\\n\"\n",
        "                        \"Name:\\nEmail:\\nPhone:\\nExperience:\\nSkills:\"\n",
        "                    )},\n",
        "                    {\"role\": \"user\", \"content\": cv_text}\n",
        "                ],\n",
        "                temperature=1,\n",
        "                max_completion_tokens=256,\n",
        "                top_p=1,\n",
        "                stream=False,\n",
        "                stop=None,\n",
        "            )\n",
        "\n",
        "            response = completion.choices[0].message.content\n",
        "            name = \"Not Provided\"\n",
        "            email = \"Not Provided\"\n",
        "            phone = \"Not Provided\"\n",
        "            experience = \"Not Provided\"\n",
        "            skills = \"Not Provided\"\n",
        "\n",
        "            if \"Name:\" in response:\n",
        "                name = response.split(\"Name:\")[1].split(\"\\n\")[0].strip()\n",
        "            if \"Email:\" in response:\n",
        "                email = response.split(\"Email:\")[1].split(\"\\n\")[0].strip()\n",
        "            if \"Phone:\" in response:\n",
        "                phone = response.split(\"Phone:\")[1].split(\"\\n\")[0].strip()\n",
        "            if \"Experience:\" in response:\n",
        "                experience = response.split(\"Experience:\")[1].split(\"\\n\")[0].strip()\n",
        "            if \"Skills:\" in response:\n",
        "                skills = response.split(\"Skills:\")[1].split(\"\\n\")[0].strip()\n",
        "\n",
        "            time.sleep(1)\n",
        "            return {\"name\": name, \"email\": email, \"phone\": phone, \"experience\": experience, \"skills\": skills}\n",
        "        except Exception as e:\n",
        "            if \"RateLimitError\" in str(e) and attempt < retries - 1:\n",
        "                time.sleep(backoff)\n",
        "            else:\n",
        "                raise e\n",
        "    return {\"name\": \"Not Provided\", \"email\": \"Not Provided\", \"phone\": \"Not Provided\", \"experience\": \"Not Provided\", \"skills\": \"Not Provided\"}\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+','', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# FastText similarity score\n",
        "def get_ft_embedding(text, ft_model):\n",
        "    tokens = word_tokenize(text)\n",
        "    if not tokens:\n",
        "        return np.zeros(ft_model.get_dimension())\n",
        "    vecs = [ft_model.get_word_vector(t) for t in tokens]\n",
        "    return np.mean(vecs, axis=0)\n",
        "\n",
        "def score_cv_with_fasttext(jd_text, cv_text, ft_model):\n",
        "    jd_vec = get_ft_embedding(jd_text, ft_model)\n",
        "    cv_vec = get_ft_embedding(cv_text, ft_model)\n",
        "    score = 1 - cosine(jd_vec, cv_vec)\n",
        "    if np.isnan(score):\n",
        "        return 0.0\n",
        "    return score\n",
        "\n",
        "# Reading PDFs or DOCX files\n",
        "def read_file(file_path: str) -> str:\n",
        "    lower_path = file_path.lower()\n",
        "    if lower_path.endswith(\".pdf\"):\n",
        "        doc = fitz.open(file_path)\n",
        "        text_pages = [page.get_text() for page in doc]\n",
        "        doc.close()\n",
        "        return \"\\n\".join(text_pages)\n",
        "    elif lower_path.endswith(\".docx\"):\n",
        "        document = docx.Document(file_path)\n",
        "        return \"\\n\".join([p.text for p in document.paragraphs])\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            return f.read()\n",
        "\n",
        "# Process JD and CVs\n",
        "@app.route('/process_jd_and_cvs', methods=['POST'])\n",
        "def process_jd_and_cvs():\n",
        "    jd_file_path = request.json.get('jd_file_path')\n",
        "    cv_folder_path = request.json.get('cv_folder_path')\n",
        "    fasttext_model_path = request.json.get('fasttext_model_path')\n",
        "\n",
        "    jd_text_raw = read_file(jd_file_path)\n",
        "    jd_text_prepped = preprocess_text(jd_text_raw)\n",
        "\n",
        "    ft_model = fasttext.load_model(fasttext_model_path)\n",
        "\n",
        "    cv_files = sorted(Path(cv_folder_path).glob(\"*.pdf\"))\n",
        "    cv_files += sorted(Path(cv_folder_path).glob(\"*.docx\"))\n",
        "\n",
        "    results = []\n",
        "    for cv_file in cv_files:\n",
        "        cv_text_raw = read_file(str(cv_file))\n",
        "        cv_text_prepped = preprocess_text(cv_text_raw)\n",
        "\n",
        "        details = extract_cv_details_groq(cv_text_raw)\n",
        "\n",
        "        # Extract passing year from the CV\n",
        "        passing_year_match = re.search(r'(\\d{4})\\s*(?:graduated|passed|completed)', cv_text_raw)\n",
        "        passing_year = passing_year_match.group(1) if passing_year_match else \"Not Provided\"\n",
        "\n",
        "        score_0_1 = score_cv_with_fasttext(jd_text_prepped, cv_text_prepped, ft_model)\n",
        "\n",
        "        result = {\n",
        "            \"name\": details[\"name\"],\n",
        "            \"email\": details[\"email\"],\n",
        "            \"phone\": details[\"phone\"],\n",
        "            \"aiExperience\": details[\"experience\"],  # Extracted AI experience\n",
        "            \"skills\": details[\"skills\"],  # Extracted skills\n",
        "            \"jdCvScore\": round(float(score_0_1) * 100, 2)  # JD-CV match score\n",
        "        }\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    output_csv = \"cv_scores.csv\"\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "    return jsonify({\"message\": \"Processed JD and CVs\", \"data\": results})\n",
        "\n",
        "# Download emails API\n",
        "@app.route('/download_emails', methods=['GET'])\n",
        "def download_emails():\n",
        "    num_emails = request.args.get('num_emails', default='all')\n",
        "\n",
        "    mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n",
        "    mail.login(EMAIL_USER, EMAIL_PASS)\n",
        "    mail.select(\"inbox\")\n",
        "\n",
        "    status, messages = mail.search(None, \"ALL\")\n",
        "    email_ids = messages[0].split()\n",
        "\n",
        "    if num_emails == 'all':\n",
        "        selected_email_ids = email_ids\n",
        "    else:\n",
        "        try:\n",
        "            num_emails = int(num_emails)\n",
        "            selected_email_ids = email_ids[:num_emails]\n",
        "        except ValueError:\n",
        "            return jsonify({\"error\": \"Invalid 'num_emails' parameter. It must be an integer or 'all'.\"}), 400\n",
        "\n",
        "    downloaded_files = []\n",
        "    for email_id in selected_email_ids:\n",
        "        res, msg_data = mail.fetch(email_id, \"(RFC822)\")\n",
        "        for response_part in msg_data:\n",
        "            if isinstance(response_part, tuple):\n",
        "                msg = email.message_from_bytes(response_part[1])\n",
        "\n",
        "                subject, encoding = decode_header(msg[\"Subject\"])[0]\n",
        "                if isinstance(subject, bytes):\n",
        "                    subject = subject.decode(encoding or \"utf-8\", errors=\"ignore\")\n",
        "                body = \"\"\n",
        "                if msg.is_multipart():\n",
        "                    for part in msg.walk():\n",
        "                        content_type = part.get_content_type()\n",
        "                        if content_type == \"text/plain\" and \"attachment\" not in str(part.get(\"Content-Disposition\")):\n",
        "                            body = part.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "                            break\n",
        "                else:\n",
        "                    body = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "\n",
        "                combined_text = f\"{subject} {body}\".lower()\n",
        "\n",
        "                if any(keyword in combined_text for keyword in KEYWORDS):\n",
        "                    for part in msg.walk():\n",
        "                        if part.get_content_disposition() == \"attachment\":\n",
        "                            filename = part.get_filename()\n",
        "                            if filename:\n",
        "                                filepath = os.path.join(ATTACHMENTS_FOLDER, filename)\n",
        "                                with open(filepath, \"wb\") as f:\n",
        "                                    f.write(part.get_payload(decode=True))\n",
        "                                downloaded_files.append(filepath)\n",
        "\n",
        "    mail.logout()\n",
        "\n",
        "    return jsonify({\"message\": \"Downloaded email attachments\", \"files\": downloaded_files})\n",
        "\n",
        "# Expose the Flask app via ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000\\\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, use_reloader=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHOaWAiPRw5Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
